---
title: "analisi preliminale"
---

```{r}
setwd('C:/Users/Elena/Desktop/Elena/Polimi/MAGISTRALE/Nonparametric statistics/Progetto/github repository/ALZHEIMER_prognonpa/Elena')
dataset_xsectional <- read.csv("oasis_cross-sectional.csv", header = T)
dataset_longitudinal <- read.csv("oasis_longitudinal.csv", header = T)
```

```{r}
library(DepthProc)
```

```{r}
head(na.omit(dataset_longitudinal[,c(8,9,11,13,14,15)]))
```

```{r}
data_n <- na.omit(dataset_longitudinal[,c(3,8,9,11,12,13,14,15)])
#data_n$M.F <- ifelse(data_n$M.F=='M', 0, 1)

data_n <- data_n[-which(data_n$Group=='Converted'),]

n1=table(data_n$Group)[1]
n2=table(data_n$Group)[2]
n <- dim(data_n)[1]

data_new <- data_n[,-1]

groups=split(data_new, data_n$Group)
# 
# med1 <- colMeans(groups$'Demented')
# med2 <- colMeans(groups$'Nondemented')

med1=depthMedian(groups$'Demented',depth_params = 'Tukey')
med2=depthMedian(groups$'Nondemented',depth_params = 'Tukey')
```


 DEVO TOGLIERE I CONVERTED E FARE SOLO SUGLI ALTRI


```{r}
t0= as.numeric((med1-med2) %*% (med1-med2))      # 
t02 <- max(abs(med2-med1)) 

B <- 1000
seed <- 2022
set.seed(seed)

tstat=numeric(B)
tstat2 <- numeric(B)
pb=progress::progress_bar$new(total=B, format = " Processing [:bar] :percent eta: :eta")  


for (b in 1:B){
  perm=sample(1:n)
  datanew.p=data_new[perm,]
  med1.p=depthMedian(datanew.p[1:n1,], list(method='Tukey'))
  med2.p=depthMedian(datanew.p[(n1+1):n,], list(method='Tukey'))
  tstat[b]= (med1.p-med2.p) %*% (med1.p-med2.p)       #
  tstat2[b] <- max(abs(med2.p-med1.p))
  pb$tick()
}

```


```{r}
plot(ecdf(tstat))
abline(v=t0, col=3)
```


```{r}
pval=sum(tstat>=t0)/B
pval
```



```{r}
plot(ecdf(tstat2))
abline(v=t02, col=3)
```


```{r}
pval=sum(tstat2>=t02)/B
pval
```





```{r}
data_n <- na.omit(dataset_longitudinal[,c(3,8,9,11,13,14)])
#data_n$M.F <- ifelse(data_n$M.F=='M', 0, 1)

n1=table(data_n$Group)[1]
n2=table(data_n$Group)[2]
n <- dim(data_n)[1]

data_new <- data_n[,-1]

groups=split(data_new, data_n$Group)
# 
# med1 <- colMeans(groups$'Demented')
# med2 <- colMeans(groups$'Nondemented')

med1=depthMedian(groups$'Demented',depth_params = 'Tukey')
med2=depthMedian(groups$'Nondemented',depth_params = 'Tukey')
```


```{r}
t0= as.numeric((med1-med2) %*% (med1-med2))      # max(abs(med2-med1)) 

B <- 1000
seed <- 2022
set.seed(seed)

tstat=numeric(B)
pb=progress::progress_bar$new(total=B, format = " Processing [:bar] :percent eta: :eta")  


for (b in 1:B){
  perm=sample(1:n)
  datanew.p=data_new[perm,]
  med1.p=depthMedian(datanew.p[1:n1,], list(method='Tukey'))
  med2.p=depthMedian(datanew.p[(n1+1):n,], list(method='Tukey'))
  tstat[b]= (med1.p-med2.p) %*% (med1.p-med2.p)       #max(abs(med2.p-med1.p))
  pb$tick()
}

```


```{r}
plot(ecdf(tstat))
abline(v=t0, col=3)
```


```{r}
pval=sum(tstat>=t0)/B
pval
```




```{r}
data_n <- na.omit(dataset_longitudinal[,c(3,8,9,11,13,14)])
#data_n$M.F <- ifelse(data_n$M.F=='M', 0, 1)


n1=table(data_n$Group)[1]
n2=table(data_n$Group)[2]
n <- dim(data_n)[1]

data_new <- scale(data_n[,-1])

groups=split(data_new, data_n$Group)

# med1 <- colMeans(groups$'Demented')
# med2 <- colMeans(groups$'Nondemented')

med1=depthMedian(groups$'Demented',depth_params = 'Tukey')
med2=depthMedian(groups$'Nondemented',depth_params = 'Tukey')
```


```{r}
t0= as.numeric((med1-med2) %*% (med1-med2))      # max(abs(med2-med1)) 

B <- 1000
seed <- 2022
set.seed(seed)

tstat=numeric(B)
pb=progress::progress_bar$new(total=B, format = " Processing [:bar] :percent eta: :eta")  


for (b in 1:B){
  perm=sample(1:n)
  datanew.p=data_new[perm,]
  med1.p=depthMedian(datanew.p[1:n1,], list(method='Tukey'))
  med2.p=depthMedian(datanew.p[(n1+1):n,], list(method='Tukey'))
  tstat[b]= (med1.p-med2.p) %*% (med1.p-med2.p)       #max(abs(med2.p-med1.p))
  pb$tick()
}

```


```{r}
plot(ecdf(tstat))
abline(v=t0, col=3)
```


```{r}
pval=sum(tstat>=t0)/B
pval
```








```{r}
t1 = week[1:5,]
t2 = week[6:7,]

t1.mean = colMeans(t1)
t2.mean = colMeans(t2)

matplot(seq(0,47)/2,t(rbind(t1.mean,t2.mean)), type='l', col=c(1,2), lty=1)
```

Let's compute the test statistic

```{r}
n1 = dim(t1)[1]
n2 = dim(t2)[1]
n  = n1 + n2

T20 = as.numeric((t1.mean-t2.mean) %*% (t1.mean-t2.mean))
T20
```

To perform our test, we need to confront the test statistic against the (permutational) distribution of it under $H_0$.

```{r}
# Estimating the permutational distribution under H0

T2 = numeric(B)
set.seed(seed)
for(perm in 1:B){
  # Random permutation of indexes
  # When we apply permutations in a multivariate case, we keep the units together
  # i.e., we only permute the rows of the data matrix
  t_pooled = rbind(t1,t2)
  permutation = sample(n)
  t_perm = t_pooled[permutation,]
  t1_perm = t_perm[1:n1,]
  t2_perm = t_perm[(n1+1):n,]
  
  # Evaluation of the test statistic on permuted data
  t1.mean_perm = colMeans(t1_perm)
  t2.mean_perm = colMeans(t2_perm)
  T2[perm]  = (t1.mean_perm-t2.mean_perm) %*% (t1.mean_perm-t2.mean_perm) 
}
```

Let's now see the shape of the permutational distribution, compared with the computed test statistic (the green vertical line...)

```{r}
hist(T2,xlim=range(c(T2,T20)))
abline(v=T20,col=3,lwd=4)

plot(ecdf(T2))
abline(v=T20,col=3,lwd=4)
```

The P-value will be amazingly low... but let's try to calculate it nevertheless

```{r}
p_val = sum(T2>=T20)/B
p_val
```













